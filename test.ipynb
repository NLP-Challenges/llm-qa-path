{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup OpenAI API\n",
    "load_dotenv()\n",
    "chat = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[{\"SOURCE\": \"Wikipedia\", \"CONTENT\": \"Während einige Götter Krankheit und Tod bringen, heilen andere Kranke und beschützen die Toten, und andere Götter wiederum vereinen diese beiden Funktionen. Bekannt ist der griechische Gott Asklepios der Medizin und Heilkunst. In China wurde der Arzt Baosheng Dadi nach seinem Tod zum Gott der Medizin erhoben. Zu den Göttern, die Krankheiten herbeiführen, zählen Pakoro Kamui bei den Ainu sowie Lugal-Irra und Namtar in Mesopotamien. Letzterem wurde nachgesagt, 60 verschiedene Krankheiten verursachen zu können. In den Veden bringt Rudra oft Krankheit und Verwüstung, wird aber auch als Heiler verehrt. Die Eigenschaften, die Totengöttern zugeschrieben werden, hängen von den religiös-kulturellen Vorstellungen des Geschehens nach dem Tode ab. Die ägyptische Göttin Hathor behütet die Toten, und im Hinduismus richtet Yama über die Toten..\"}]',\n",
       " '[{\"SOURCE\": \"Quelle: Wikipedia\", \"CONTENT\": \"Ein auf eine Gleichspannung  aufgeladener realer Kondensator entlädt sich mit der Zeit von selbst. Dieser Effekt kann durch einen endlichen \\'\\'Isolationswiderstand\\'\\'  des Dielektrikums beschrieben werden, der zu einem idealen Kondensator mit der Kapazität \\'\\'C\\'\\' parallel geschaltet ist. Der fließende Strom wird als Leckstrom bezeichnet; er wird bei Baureihen häufig als Funktion der Kapazität spezifiziert. Der zeitliche Verlauf der absinkenden Kondensatorspannung hat die Form die \\'\\'Selbstentladezeitkonstante\\'\\' ist. Nach der Zeit  ist die Kondensatorspannung  auf 37 % des Anfangswertes abgesunken. Die Selbstentladezeitkonstante ist ein Maß für die Isolation des Dielektrikums zwischen den Elektroden eines Kondensators. Diese Zeitkonstante ist beispielsweise wichtig, wenn ein Kondensator als zeitbestimmendes Glied (zum Beispiel in Zeitrelais) oder zur Speicherung eines Spannungswertes wie in einer Abtast-Halte-Schaltung oder Integrierern eingesetzt wird. Keramikkondensatoren der Klasse\\xa01 müssen gemäß geltender Normen einen Isolationswiderstand von mindestens 10\\xa0GΩ, die der Klasse\\xa02 mindestens 4\\xa0GΩ oder eine Selbstentladezeitkonstante von mindestens 100\\xa0s besitzen.\"}, {\"SOURCE\": \"Website: www.elektronik-kompendium.de\", \"CONTENT\": \"Der typische Wert liegt meist darüber. Kunststoff-Folienkondensatoren haben typischerweise einen Isolationswiderstand zwischen 6 und 12\\xa0GΩ. Das entspricht für Kondensatoren im µF-Bereich einer Selbstentladezeitkonstante von 2000 bis 4000\\xa0s. Bei Elektrolytkondensatoren wird der Isolationswiderstand des Oxidschichtdielektrikums über den Reststrom des Kondensators definiert. Der Isolationswiderstand bzw. die Selbstentladezeitkonstante ist teilweise stark temperaturabhängig und sinkt mit steigender Temperatur. Der Isolationswiderstand bzw. die Selbstentladezeitkonstante darf nicht verwechselt werden mit der Isolierung des Bauelementes gegenüber der Umgebung..\"}]']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(load_from_disk(\"data/processed/ft_dataset.hf\", keep_in_memory=True))\n",
    "\n",
    "def get_chunks(series: pd.Series, max_chunks: int = 4):\n",
    "    \"\"\"\n",
    "    Funktion zum Aufteilen von Texten in der Series in Chunks.\n",
    "    Jeder Text wird zuerst in Sätze aufgeteilt und dann in Chunks unterteilt.\n",
    "    \n",
    "    :param series: pandas Series mit Texten.\n",
    "    :param max_chunks: Maximale Anzahl von Chunks, in die ein Text aufgeteilt werden kann.\n",
    "    :return: Eine neue Series, wobei jeder Eintrag eine Liste von Chunks ist.\n",
    "    \"\"\"\n",
    "    \n",
    "    def split_text(text:str, num_chunks:int):\n",
    "        return [\" \".join(splits) for splits in np.array_split([sentence+\".\" for sentence in text.split(\". \")], num_chunks)] #get chunks\n",
    "    \n",
    "    chunksize = np.random.choice(list(range(1, max_chunks+1)), size=len(series))\n",
    "    \n",
    "    return [split_text(text, chunksize[i]) for i, text in enumerate(series)]\n",
    "\n",
    "def get_source(text:str):\n",
    "    template = (\n",
    "        \"\"\"Nachfolgend erhälst du einen Text. Bitte erstelle zu diesem Textabschnitt eine mögliche Quelle.\n",
    "        Die Quelle soll möglichst kurz und ohne Zusatzinformationen sein.\n",
    "        Beispiele: \n",
    "        - Wikipedia\n",
    "        - Website xy\n",
    "        - (Weitere eigene Quellen)\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "    human_template = \"{message}\"\n",
    "    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "    messages = chat_prompt.format_prompt(message=text).to_messages()\n",
    "\n",
    "    return chat(messages).content\n",
    "\n",
    "def gpt_formatter(series: pd.Series):\n",
    "    formatted = []\n",
    "    for chunks in series:\n",
    "        formatted.append(json.dumps([{\"SOURCE\":get_source(text), \"CONTENT\":text} for text in chunks], ensure_ascii=False))\n",
    "\n",
    "    return formatted\n",
    "\n",
    "df[\"context\"] = get_chunks(df.context)\n",
    "gpt_formatter(df.context[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Quelle: Wikipedia')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_source(df.context[3][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot-qa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
