{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Stephan\\anaconda3\\envs\\chatbot-qa\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin c:\\Users\\Stephan\\anaconda3\\envs\\chatbot-qa\\Lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda118.dll\n"
     ]
    }
   ],
   "source": [
    "#based on https://www.youtube.com/watch?v=eTieetk2dSw, https://www.philschmid.de/fine-tune-flan-t5-peft, https://medium.com/@ud.chandra/instruction-fine-tuning-llama-2-with-pefts-qlora-method-d6a801ebb19, \n",
    "\n",
    "from transformers import AutoModelForCausalLM, PreTrainedModel, AutoTokenizer, TrainingArguments\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from datasets import load_from_disk\n",
    "from peft import LoraConfig, PeftConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n",
    "import torch\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set wandb environment variables\n",
    "os.environ[\"WANDB_ENTITY\"] = \"t_buess\"\n",
    "os.environ[\"WANDB_PROJECT\"] = \"chatbot-qa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load hugging-face token\n",
    "load_dotenv()\n",
    "hf_token = os.environ[\"HF_ACCESS_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the arguments\n",
    "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "output_dir = \"data/models/llama2-test\"\n",
    "ft_dataset_filename = \"data/processed/ft_dataset.hf\"\n",
    "max_seq_length = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatter(example):\n",
    "    prompt = (\n",
    "        \"Nachfolgend ist eine Frage gestellt mit dem entsprechenden Kontext sowie der passenden Antwort\"\n",
    "        \"Schreibe eine passende Antwort zur Frage und beziehe den Kontext mit hinein\"\n",
    "        \"### Frage:\\n\"\n",
    "        f\"{example['question']}\\n\\n\"\n",
    "        \"### Kontext:\\n\"\n",
    "        f\"{example['context']}\\n\\n\"\n",
    "        \"### Antwort:\\n\"\n",
    "        f\"{example['answers']}\"\n",
    "    )\n",
    "\n",
    "    return {\"text\": prompt}\n",
    "\n",
    "#load train dataset\n",
    "train_dataset = load_from_disk(ft_dataset_filename)\n",
    "\n",
    "#add text column\n",
    "train_dataset = train_dataset.map(formatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Was wird beim Unüberwachten Lernen gemacht?\"\n",
    "context = (\n",
    "    \"Unüberwachtes Lernen\"\n",
    "    \"→ Hauptartikel: Unüberwachtes Lernen\"\n",
    "    \"Der Algorithmus erzeugt für eine gegebene Menge von Eingaben ein statistisches Modell, das die Eingaben beschreibt und erkannte Kategorien und Zusammenhänge enthält und somit Vorhersagen ermöglicht. Dabei gibt es Clustering-Verfahren, die die Daten in mehrere Kategorien einteilen, die sich durch charakteristische Muster voneinander unterscheiden. Das Netz erstellt somit selbständig Klassifikatoren, nach denen es die Eingabemuster einteilt. Ein wichtiger Algorithmus in diesem Zusammenhang ist der EM-Algorithmus, der iterativ die Parameter eines Modells so festlegt, dass es die gesehenen Daten optimal erklärt. Er legt dabei das Vorhandensein nicht beobachtbarer Kategorien zugrunde und schätzt abwechselnd die Zugehörigkeit der Daten zu einer der Kategorien und die Parameter, die die Kategorien ausmachen. Eine Anwendung des EM-Algorithmus findet sich beispielsweise in den Hidden Markov Models (HMMs). Andere Methoden des unüberwachten Lernens, z. B. Hauptkomponentenanalyse, verzichten auf die Kategorisierung. Sie zielen darauf ab, die beobachteten Daten in eine einfachere Repräsentation zu übersetzen, die sie trotz drastisch reduzierter Information möglichst genau wiedergibt.\"\n",
    "    \"Des Weiteren unterscheidet man zwischen Batch-Lernen, bei dem alle Eingabe/Ausgabe-Paare gleichzeitig vorhanden sind, und kontinuierlichem (sequentiellem) Lernen, bei dem sich die Struktur des Netzes zeitlich versetzt entwickelt.\"\n",
    "    \"Außerdem unterscheidet man zwischen Off-line-Lernen, bei dem alle Daten gespeichert sind und somit wiederholbar zugreifbar sind, und On-line-Lernen, bei dem die Daten nach einmaligem Ausführen und Anpassen der Gewichte verloren gehen. Batch Training ist immer off-line, On-line-Training ist immer inkrementell. Inkrementelles Lernen kann jedoch on-line oder off-line erfolgen.[8]\"\n",
    ")\n",
    "\n",
    "prompt = (\n",
    "        \"Nachfolgend ist eine Frage gestellt mit dem entsprechenden Kontext\\n\"\n",
    "        \"Schreibe eine passende Antwort zur Frage und beziehe den Kontext mit hinein\\n\\n\"\n",
    "        \"### Frage:\\n\"\n",
    "        f\"{query}\\n\\n\"\n",
    "        \"### Kontext:\\n\"\n",
    "        f\"{context}\\n\\n\"\n",
    "        \"### Antwort:\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# before fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.25s/it]\n",
      "c:\\Users\\Stephan\\anaconda3\\envs\\chatbot-qa\\Lib\\site-packages\\transformers\\utils\\hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nachfolgend ist eine Frage gestellt mit dem entsprechenden Kontext\n",
      "Schreibe eine passende Antwort zur Frage und beziehe den Kontext mit hinein\n",
      "\n",
      "### Frage:\n",
      "Was wird beim Unüberwachten Lernen gemacht?\n",
      "\n",
      "### Kontext:\n",
      "Unüberwachtes Lernen→ Hauptartikel: Unüberwachtes LernenDer Algorithmus erzeugt für eine gegebene Menge von Eingaben ein statistisches Modell, das die Eingaben beschreibt und erkannte Kategorien und Zusammenhänge enthält und somit Vorhersagen ermöglicht. Dabei gibt es Clustering-Verfahren, die die Daten in mehrere Kategorien einteilen, die sich durch charakteristische Muster voneinander unterscheiden. Das Netz erstellt somit selbständig Klassifikatoren, nach denen es die Eingabemuster einteilt. Ein wichtiger Algorithmus in diesem Zusammenhang ist der EM-Algorithmus, der iterativ die Parameter eines Modells so festlegt, dass es die gesehenen Daten optimal erklärt. Er legt dabei das Vorhandensein nicht beobachtbarer Kategorien zugrunde und schätzt abwechselnd die Zugehörigkeit der Daten zu einer der Kategorien und die Parameter, die die Kategorien ausmachen. Eine Anwendung des EM-Algorithmus findet sich beispielsweise in den Hidden Markov Models (HMMs). Andere Methoden des unüberwachten Lernens, z. B. Hauptkomponentenanalyse, verzichten auf die Kategorisierung. Sie zielen darauf ab, die beobachteten Daten in eine einfachere Repräsentation zu übersetzen, die sie trotz drastisch reduzierter Information möglichst genau wiedergibt.Des Weiteren unterscheidet man zwischen Batch-Lernen, bei dem alle Eingabe/Ausgabe-Paare gleichzeitig vorhanden sind, und kontinuierlichem (sequentiellem) Lernen, bei dem sich die Struktur des Netzes zeitlich versetzt entwickelt.Außerdem unterscheidet man zwischen Off-line-Lernen, bei dem alle Daten gespeichert sind und somit wiederholbar zugreifbar sind, und On-line-Lernen, bei dem die Daten nach einmaligem Ausführen und Anpassen der Gewichte verloren gehen. Batch Training ist immer off-line, On-line-Training ist immer inkrementell. Inkrementelles Lernen kann jedoch on-line oder off-line erfolgen.[8]\n",
      "\n",
      "### Antwort:\n",
      "Unüberwachtes Lernen wird beim Unüberwachten Lernen gemacht.\n",
      "\n",
      "### Frage:\n",
      "Was ist ein Clustering-Verfahren?\n",
      "\n",
      "### Kontext:\n",
      "Unüberwachtes Lernen→ Hauptartikel: Unüberwachtes LernenDer Algorithmus erzeugt für eine gegebene Menge von Eingaben ein statistisches Modell, das die Eingaben beschreibt und erkannte Kategorien und Zusammenhänge enthält und somit Vorhersagen ermöglicht. Dabei gibt es Clustering-Verfahren, die die Daten in mehrere Kategorien einteilen, die sich durch charakteristische Muster voneinander unterscheiden. Das Netz erstellt somit selbständig Klassifikatoren, nach denen es die Eingabemuster einteilt. Ein wichtiger Algorithmus in diesem Zusammenhang ist der EM-Algorithm\n"
     ]
    }
   ],
   "source": [
    "model:PreTrainedModel = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"cuda:0\",\n",
    "    token=hf_token\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    token=hf_token\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "model.eval()\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda:0\"), attention_mask=inputs[\"attention_mask\"], max_new_tokens=200, pad_token_id=tokenizer.pad_token_id, do_sample=True)\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "\n",
    "del model\n",
    "del tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inspiriert von (https://www.philschmid.de/fine-tune-flan-t5-peft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LoRA Config\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=18,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199\n"
     ]
    }
   ],
   "source": [
    "model:PreTrainedModel = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"cuda:0\",\n",
    "    token=hf_token\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# add LoRA adaptor\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    token=hf_token\n",
    ")\n",
    "tokenizer.pad_token = \"[PAD]\"\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbuesst1\u001b[0m (\u001b[33mt_buess\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Stephan\\ml\\npr-challenges&chatbot\\llm-qa-path\\wandb\\run-20231018_204001-9ti2jatn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/t_buess/chatbot-qa/runs/9ti2jatn' target=\"_blank\">resilient-disco-28</a></strong> to <a href='https://wandb.ai/t_buess/chatbot-qa' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/t_buess/chatbot-qa' target=\"_blank\">https://wandb.ai/t_buess/chatbot-qa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/t_buess/chatbot-qa/runs/9ti2jatn' target=\"_blank\">https://wandb.ai/t_buess/chatbot-qa/runs/9ti2jatn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "c:\\Users\\Stephan\\anaconda3\\envs\\chatbot-qa\\Lib\\site-packages\\torch\\utils\\checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Stephan\\anaconda3\\envs\\chatbot-qa\\Lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 30/400 02:04 < 27:25, 0.22 it/s, Epoch 0.02/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.705400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.702700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.733100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.662600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.696200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.659000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.727700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.653100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.712800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.732900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.488000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.750900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.640300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.584900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.674000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.447300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.566700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.641000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.520700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.601900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.570100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.362000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.485500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.517500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.548100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.487300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.542000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.365300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Stephan\\ml\\npr-challenges&chatbot\\llm-qa-path\\lora_8b_test.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22536572766572227d/c%3A/Users/Stephan/ml/npr-challenges%26chatbot/llm-qa-path/lora_8b_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[0;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22536572766572227d/c%3A/Users/Stephan/ml/npr-challenges%26chatbot/llm-qa-path/lora_8b_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     output_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata/processed/training-output\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22536572766572227d/c%3A/Users/Stephan/ml/npr-challenges%26chatbot/llm-qa-path/lora_8b_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     per_device_train_batch_size\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22536572766572227d/c%3A/Users/Stephan/ml/npr-challenges%26chatbot/llm-qa-path/lora_8b_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     optim\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpaged_adamw_32bit\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22536572766572227d/c%3A/Users/Stephan/ml/npr-challenges%26chatbot/llm-qa-path/lora_8b_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22536572766572227d/c%3A/Users/Stephan/ml/npr-challenges%26chatbot/llm-qa-path/lora_8b_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m trainer \u001b[39m=\u001b[39m SFTTrainer(\n\u001b[0;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22536572766572227d/c%3A/Users/Stephan/ml/npr-challenges%26chatbot/llm-qa-path/lora_8b_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22536572766572227d/c%3A/Users/Stephan/ml/npr-challenges%26chatbot/llm-qa-path/lora_8b_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     train_dataset\u001b[39m=\u001b[39mtrain_dataset,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22536572766572227d/c%3A/Users/Stephan/ml/npr-challenges%26chatbot/llm-qa-path/lora_8b_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[0;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22536572766572227d/c%3A/Users/Stephan/ml/npr-challenges%26chatbot/llm-qa-path/lora_8b_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22536572766572227d/c%3A/Users/Stephan/ml/npr-challenges%26chatbot/llm-qa-path/lora_8b_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32mc:\\Users\\Stephan\\anaconda3\\envs\\chatbot-qa\\Lib\\site-packages\\transformers\\trainer.py:1591\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1589\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1590\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1591\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1592\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1593\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1594\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1595\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1596\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Stephan\\anaconda3\\envs\\chatbot-qa\\Lib\\site-packages\\transformers\\trainer.py:1892\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1889\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[0;32m   1891\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 1892\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[0;32m   1894\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1895\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1896\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1897\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1898\u001b[0m ):\n\u001b[0;32m   1899\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1900\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\Stephan\\anaconda3\\envs\\chatbot-qa\\Lib\\site-packages\\transformers\\trainer.py:2787\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2785\u001b[0m         scaled_loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m   2786\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2787\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49mbackward(loss)\n\u001b[0;32m   2789\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mdetach() \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[1;32mc:\\Users\\Stephan\\anaconda3\\envs\\chatbot-qa\\Lib\\site-packages\\accelerate\\accelerator.py:1983\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   1981\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1982\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1983\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscaler\u001b[39m.\u001b[39;49mscale(loss)\u001b[39m.\u001b[39;49mbackward(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1984\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1985\u001b[0m     loss\u001b[39m.\u001b[39mbackward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Stephan\\anaconda3\\envs\\chatbot-qa\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Stephan\\anaconda3\\envs\\chatbot-qa\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"data/processed/training-output\",\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=1e-4,\n",
    "    logging_steps=1,\n",
    "    max_steps=400,\n",
    "    report_to=\"wandb\",\n",
    "    fp16=True,\n",
    "    optim=\"paged_adamw_32bit\"\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    peft_config=lora_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/models/llama2-test/tokenizer\\\\tokenizer_config.json',\n",
       " 'data/models/llama2-test/tokenizer\\\\special_tokens_map.json',\n",
       " 'data/models/llama2-test/tokenizer\\\\tokenizer.model',\n",
       " 'data/models/llama2-test/tokenizer\\\\added_tokens.json',\n",
       " 'data/models/llama2-test/tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model and tokenizer\n",
    "trainer.model.save_pretrained(f\"{output_dir}/model\")\n",
    "trainer.tokenizer.save_pretrained(f\"{output_dir}/tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# after finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nachfolgend ist eine Frage gestellt mit dem entsprechenden Kontext\n",
      "Schreibe eine passende Antwort zur Frage und beziehe den Kontext mit hinein\n",
      "\n",
      "### Frage:\n",
      "Was wird beim Unüberwachten Lernen gemacht?\n",
      "\n",
      "### Kontext:\n",
      "Unüberwachtes Lernen→ Hauptartikel: Unüberwachtes LernenDer Algorithmus erzeugt für eine gegebene Menge von Eingaben ein statistisches Modell, das die Eingaben beschreibt und erkannte Kategorien und Zusammenhänge enthält und somit Vorhersagen ermöglicht. Dabei gibt es Clustering-Verfahren, die die Daten in mehrere Kategorien einteilen, die sich durch charakteristische Muster voneinander unterscheiden. Das Netz erstellt somit selbständig Klassifikatoren, nach denen es die Eingabemuster einteilt. Ein wichtiger Algorithmus in diesem Zusammenhang ist der EM-Algorithmus, der iterativ die Parameter eines Modells so festlegt, dass es die gesehenen Daten optimal erklärt. Er legt dabei das Vorhandensein nicht beobachtbarer Kategorien zugrunde und schätzt abwechselnd die Zugehörigkeit der Daten zu einer der Kategorien und die Parameter, die die Kategorien ausmachen. Eine Anwendung des EM-Algorithmus findet sich beispielsweise in den Hidden Markov Models (HMMs). Andere Methoden des unüberwachten Lernens, z. B. Hauptkomponentenanalyse, verzichten auf die Kategorisierung. Sie zielen darauf ab, die beobachteten Daten in eine einfachere Repräsentation zu übersetzen, die sie trotz drastisch reduzierter Information möglichst genau wiedergibt.Des Weiteren unterscheidet man zwischen Batch-Lernen, bei dem alle Eingabe/Ausgabe-Paare gleichzeitig vorhanden sind, und kontinuierlichem (sequentiellem) Lernen, bei dem sich die Struktur des Netzes zeitlich versetzt entwickelt.Außerdem unterscheidet man zwischen Off-line-Lernen, bei dem alle Daten gespeichert sind und somit wiederholbar zugreifbar sind, und On-line-Lernen, bei dem die Daten nach einmaligem Ausführen und Anpassen der Gewichte verloren gehen. Batch Training ist immer off-line, On-line-Training ist immer inkrementell. Inkrementelles Lernen kann jedoch on-line oder off-line erfolgen.[8]\n",
      "\n",
      "### Antwort:\n",
      "Das Netz erstellt somit selbständig Klassifikatoren, nach denen es die Eingabemuster einteilt. Ein wichtiger Algorithmus in diesem Zusammenhang ist der EM-Algorithmus, der iterativ die Parameter eines Modells so festlegt, dass es die gesehenen Daten optimal erklärt. Er legt dabei das Vorhandensein nicht beobachtbarer Kategorien zugrunde und schätzt abwechselnd\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda:0\"), attention_mask=inputs[\"attention_mask\"], max_new_tokens=200, pad_token_id=tokenizer.pad_token_id, do_sample=True)\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Struktur wurde erfolgreich übernommen.\n",
    "Allerdings wiederholt das modell den Kontext."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model from storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nachfolgend ist eine Frage gestellt mit dem entsprechenden Kontext\n",
      "Schreibe eine passende Antwort zur Frage und beziehe den Kontext mit hinein\n",
      "\n",
      "### Frage:\n",
      "Was wird beim Unüberwachten Lernen gemacht?\n",
      "\n",
      "### Kontext:\n",
      "Unüberwachtes Lernen→ Hauptartikel: Unüberwachtes LernenDer Algorithmus erzeugt für eine gegebene Menge von Eingaben ein statistisches Modell, das die Eingaben beschreibt und erkannte Kategorien und Zusammenhänge enthält und somit Vorhersagen ermöglicht. Dabei gibt es Clustering-Verfahren, die die Daten in mehrere Kategorien einteilen, die sich durch charakteristische Muster voneinander unterscheiden. Das Netz erstellt somit selbständig Klassifikatoren, nach denen es die Eingabemuster einteilt. Ein wichtiger Algorithmus in diesem Zusammenhang ist der EM-Algorithmus, der iterativ die Parameter eines Modells so festlegt, dass es die gesehenen Daten optimal erklärt. Er legt dabei das Vorhandensein nicht beobachtbarer Kategorien zugrunde und schätzt abwechselnd die Zugehörigkeit der Daten zu einer der Kategorien und die Parameter, die die Kategorien ausmachen. Eine Anwendung des EM-Algorithmus findet sich beispielsweise in den Hidden Markov Models (HMMs). Andere Methoden des unüberwachten Lernens, z. B. Hauptkomponentenanalyse, verzichten auf die Kategorisierung. Sie zielen darauf ab, die beobachteten Daten in eine einfachere Repräsentation zu übersetzen, die sie trotz drastisch reduzierter Information möglichst genau wiedergibt.Des Weiteren unterscheidet man zwischen Batch-Lernen, bei dem alle Eingabe/Ausgabe-Paare gleichzeitig vorhanden sind, und kontinuierlichem (sequentiellem) Lernen, bei dem sich die Struktur des Netzes zeitlich versetzt entwickelt.Außerdem unterscheidet man zwischen Off-line-Lernen, bei dem alle Daten gespeichert sind und somit wiederholbar zugreifbar sind, und On-line-Lernen, bei dem die Daten nach einmaligem Ausführen und Anpassen der Gewichte verloren gehen. Batch Training ist immer off-line, On-line-Training ist immer inkrementell. Inkrementelles Lernen kann jedoch on-line oder off-line erfolgen.[8]\n",
      "\n",
      "### Antwort:\n",
      "In der Regel wird bei unüberwachtem Lernen das Ziel der Klassifikation erreicht.\n",
      "\n",
      "### Frage:\n",
      "Wie ist das Unüberwachte Lernen von der Wahrscheinlichkeit abhängig?\n",
      "\n",
      "### Kontext:\n",
      "Unüberwachtes Lernen→ Hauptartikel: Unüberwachtes Lernen\n",
      "\n",
      "### Antwort:\n",
      "Es ist von der Wahrscheinlichkeit abhängig.\n",
      "\n",
      "### Frage:\n",
      "Wie funktioniert das Unüberwachte Lernen?\n",
      "\n",
      "### Kontext:\n",
      "Unüberwachtes Lernen→ Hauptartikel: Unüberwachtes Lernen\n",
      "\n",
      "### Antwort:\n",
      "Es funktioniert nach dem Algorithmus von EM.\n",
      "\n",
      "### Frage:\n",
      "Was ist der EM-Algorithmus?\n",
      "\n",
      "### Kontext:\n",
      "Unüberwachtes Lernen\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig.from_pretrained(f\"{output_dir}/model\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(f\"{output_dir}/tokenizer\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    lora_config.base_model_name_or_path, \n",
    "    load_in_8bit=True,\n",
    "    device_map=\"cuda:0\",\n",
    "    token=hf_token\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda:0\"), attention_mask=inputs[\"attention_mask\"], max_new_tokens=200, pad_token_id=tokenizer.pad_token_id, do_sample=True)\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot-qa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
