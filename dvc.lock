schema: '2.0'
stages:
  build_corpus:
    cmd: python src/stages/build_corpus.py data/raw/example_context.txt data/processed/corpus.pkl
    deps:
    - path: data/raw/example_context.txt
      hash: md5
      md5: 6f1ec549bb9074a2fe151ca623eca5c8
      size: 7161
    - path: src/stages/build_corpus.py
      hash: md5
      md5: 76f8ce2f4997acf627532affdc6369d5
      size: 918
    outs:
    - path: data/processed/corpus.pkl
      hash: md5
      md5: c5bff24c94fd2a5433666630fa7bc3f2
      size: 7363
  build_embedder:
    cmd: python src/stages/build_embedder.py "sentence-transformers/distiluse-base-multilingual-cased-v1"
      data/processed/embedder.pkl
    deps:
    - path: src/stages/build_embedder.py
      hash: md5
      md5: 5f190a62a322f0413d8dfa7555898b85
      size: 762
    outs:
    - path: data/processed/embedder.pkl
      hash: md5
      md5: c1ff39d790a2ae28be9b0c976a0aa5d0
      size: 542838819
  build_vectorstore:
    cmd: python src/stages/build_vectorstore.py data/processed/corpus.pkl data/processed/embedder.pkl
      data/processed/chroma
    deps:
    - path: data/processed/corpus.pkl
      hash: md5
      md5: c5bff24c94fd2a5433666630fa7bc3f2
      size: 7363
    - path: data/processed/embedder.pkl
      hash: md5
      md5: c1ff39d790a2ae28be9b0c976a0aa5d0
      size: 542838819
    - path: src/stages/build_vectorstore.py
      hash: md5
      md5: e4282f990112524267e168ce701b76de
      size: 1188
    outs:
    - path: data/processed/chroma
      hash: md5
      md5: 0563712d6bdc2a248538c3a05b0482d9.dir
      size: 2400996
      nfiles: 5
  load_vectorstore:
    cmd: python src/stages/load_vectorstore.py data/processed/chroma data/processed/embedder.pkl
      "Wo braucht es einen agenten?"
    deps:
    - path: data/processed/chroma
      hash: md5
      md5: 0563712d6bdc2a248538c3a05b0482d9.dir
      size: 2400996
      nfiles: 5
    - path: data/processed/embedder.pkl
      hash: md5
      md5: c1ff39d790a2ae28be9b0c976a0aa5d0
      size: 542838819
    - path: src/stages/load_vectorstore.py
      hash: md5
      md5: d2db77ce166cbb58f50307ee8136b6a3
      size: 2032
  build_ft_dataset:
    cmd: python src/stages/build_ft_dataset.py data/processed/ft_dataset.hf
    deps:
    - path: src/stages/build_ft_dataset.py
      hash: md5
      md5: e39f0ee592bc35412be4f71da5886f06
      size: 1568
    outs:
    - path: data/processed/ft_dataset.hf
      hash: md5
      md5: 094a8d216f97b748083d1e44fa9e4680.dir
      size: 16029946
      nfiles: 3
  train_llm:
    cmd: python src/stages/train_llm.py train_llm data/processed/ft_dataset.hf ./data/models/llama2-qa-fine-tuned
    deps:
    - path: data/processed/ft_dataset.hf
      hash: md5
      md5: 094a8d216f97b748083d1e44fa9e4680.dir
      size: 16029946
      nfiles: 3
    - path: src/stages/train_llm.py
      hash: md5
      md5: 6fb585c270b74ecd661525f6142e5bbe
      size: 4366
    params:
      params.yaml:
        train_llm:
          wandb_params:
            entity: t_buess
            project: chatbot-qa
          model_params:
            base_model_id: meta-llama/Llama-2-7b-hf
            max_seq_length: 4096
          training_config:
            batch_size: 1
            grad_accumulation_steps: 16
            optimizer: paged_adamw_32bit
            learning_rate: 1e-05
            max_steps: 400
            device_map: auto
          LoraConfig:
            r: 8
            lora_alpha: 8
            lora_dropout: 0.05
            bias: none
            task_type: CAUSAL_LM
          BitsAndBytesConfig:
            load_in_4bit: true
            bnb_4bit_use_double_quant: true
            bnb_4bit_quant_type: nf4
            bnb_4bit_compute_dtype: torch.bfloat16
    outs:
    - path: ./data/models/llama2-qa-fine-tuned
      hash: md5
      md5: 09795a72f5a967d05e6dd9af53c134cd.dir
      size: 19168085
      nfiles: 8
  load_llm:
    cmd: python src/stages/load_llm.py ./data/models/llama2-qa-fine-tuned "Wann wurde
      Python erfunden? Sei so präzise wie möglich." "Die Sprache wurde Anfang der
      1990er Jahre von Guido van Rossum am Centrum Wiskunde & Informatica in Amsterdam
      als Nachfolger für die Programmier-Lehrsprache ABC entwickelt und war ursprünglich
      für das verteilte Betriebssystem Amoeba gedacht. Der Name geht nicht, wie das
      Logo vermuten lässt, auf die gleichnamige Schlangengattung Python zurück, sondern
      bezog sich ursprünglich auf die englische Komikergruppe Monty Python. In der
      Dokumentation finden sich daher auch einige Anspielungen auf Sketche aus dem
      Flying Circus. Trotzdem etablierte sich die Assoziation zur Schlange, was sich
      unter anderem in der Programmiersprache Cobra[16] sowie dem Python-Toolkit „Boa“[17]
      äußert. Die erste Vollversion erschien im Januar 1994 unter der Bezeichnung
      Python 1.0. Gegenüber früheren Versionen wurden einige Konzepte der funktionalen
      Programmierung implementiert, die allerdings später wieder aufgegeben wurden.[18]
      Von 1995 bis 2000 erschienen neue Versionen, die fortlaufend als Python 1.1,
      1.2 etc. bezeichnet wurden."
    deps:
    - path: ./data/models/llama2-qa-fine-tuned
      hash: md5
      md5: 09795a72f5a967d05e6dd9af53c134cd.dir
      size: 19168085
      nfiles: 8
    - path: src/stages/load_llm.py
      hash: md5
      md5: ee83ecd2212aeac611396f599aa8005d
      size: 2413
